# Advanced Machine Learning 02460 - Project
## Supervisor meeting - Week 3
**17-03-2016**

### Agenda
1. Progress / status
    * Show "results"
    * Question about algorithm
2. Plan
3. Other


### Minutes

1. 
2. Plan
    - Fix "push" function
    - Implement loss function
    - Update alpha parameter
    - Try with larger data sets -> See where we can optimize our algorithm
    - Ball-trees and kD-trees
    - Maybe consider Stochastic gradient descent?
        - This will probably require a lot of book keeping of neighbours, targets and impostors
3. The gradient should be a dim \times dim matrix and not a number as our previous code had implemented

